<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>问题汇总 - lijun note</title><meta name="description" content="存在的问题 重构 出现的原因： 认为编码器对于正常事件有较低重构误差而异常事件的重构误差更大，以此能够分辨正常事件和异常事件 问题 正常样本和异常样本都可以很好地重构，从而无法发现异常值 它们通常陷入“Identity Shortcut”，”相同捷径”问题是指在机器学习中模型陷入将输入数据直接返回作为输出的低效策略。这种策略使得模型难以检测异常样本，并且在统一数据分布下尤为明显。学习”相同捷径”似乎是一种简单而低成本的解决方案，但它无法对输入数据进行有意义的转换和学习。 半监督学习 出现的原因： 减少数据标注工作，只需要正常事件即可 现实生活中异常事件有无限种可能，因此现实生活中非正常的事件即为异常事件的理念应用到训练模式中 问题： 在仅对正常数据进行训练的模型在将异常数据注入训练时无法保持稳健。 通常会触发误报，因为仅通过正常视频不借助任何先验知识本质上不适合定义正常和异常 忽略正常和异常间的关系 正常事件也是无限的，未见过的正常事件很有可能被识别为异常 记忆机制MEMORY 出现的原因： 由于正常（或异常）事件具有多样性，单靠一种网络难以表示所有正常（或异常）事件，因此加入记忆机制，存储不同类型正常（或异常）事件的原型（学习不同类型分布）。一个事件通过相似性对比可以表示为多个原型的组合 问题： 建立存储体需要额外的存储空间* 来自主观假设的固定原型数量忽略了数据特征差异和多样性* *观点来自于： Dynamic Local Aggregation Network with Adaptive Clusterer for Anomaly Detection 一些文献的memory为存储离线训练好的静态原型，难以适应未知事件 MIL学习 出现的原因： 能够对只有视频级别标签的数据进行训练，得到片段级别的标签 问题： MIL 会出现许多误报，因为它很容易偏向于具有简单上下文的异常片段，被具有相同偏差的正常片段所迷惑，并错过具有不同模式的异常、 两阶段自训练的方式，不可靠的伪标签会影响后续模型的训练 伪标签生成器中使用的排名损失忽略了异常事件的完整性。原因是，一个异常视频可能包含多个异常片段，但 MIL 旨在仅检测最有可能的一个&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://pure419.github.io/wen-ti-hui-zong.html"><link rel="alternate" type="application/atom+xml" href="https://pure419.github.io/feed.xml"><link rel="alternate" type="application/json" href="https://pure419.github.io/feed.json"><meta property="og:title" content="问题汇总"><meta property="og:site_name" content="lijun note"><meta property="og:description" content="存在的问题 重构 出现的原因： 认为编码器对于正常事件有较低重构误差而异常事件的重构误差更大，以此能够分辨正常事件和异常事件 问题 正常样本和异常样本都可以很好地重构，从而无法发现异常值 它们通常陷入“Identity Shortcut”，”相同捷径”问题是指在机器学习中模型陷入将输入数据直接返回作为输出的低效策略。这种策略使得模型难以检测异常样本，并且在统一数据分布下尤为明显。学习”相同捷径”似乎是一种简单而低成本的解决方案，但它无法对输入数据进行有意义的转换和学习。 半监督学习 出现的原因： 减少数据标注工作，只需要正常事件即可 现实生活中异常事件有无限种可能，因此现实生活中非正常的事件即为异常事件的理念应用到训练模式中 问题： 在仅对正常数据进行训练的模型在将异常数据注入训练时无法保持稳健。 通常会触发误报，因为仅通过正常视频不借助任何先验知识本质上不适合定义正常和异常 忽略正常和异常间的关系 正常事件也是无限的，未见过的正常事件很有可能被识别为异常 记忆机制MEMORY 出现的原因： 由于正常（或异常）事件具有多样性，单靠一种网络难以表示所有正常（或异常）事件，因此加入记忆机制，存储不同类型正常（或异常）事件的原型（学习不同类型分布）。一个事件通过相似性对比可以表示为多个原型的组合 问题： 建立存储体需要额外的存储空间* 来自主观假设的固定原型数量忽略了数据特征差异和多样性* *观点来自于： Dynamic Local Aggregation Network with Adaptive Clusterer for Anomaly Detection 一些文献的memory为存储离线训练好的静态原型，难以适应未知事件 MIL学习 出现的原因： 能够对只有视频级别标签的数据进行训练，得到片段级别的标签 问题： MIL 会出现许多误报，因为它很容易偏向于具有简单上下文的异常片段，被具有相同偏差的正常片段所迷惑，并错过具有不同模式的异常、 两阶段自训练的方式，不可靠的伪标签会影响后续模型的训练 伪标签生成器中使用的排名损失忽略了异常事件的完整性。原因是，一个异常视频可能包含多个异常片段，但 MIL 旨在仅检测最有可能的一个&hellip;"><meta property="og:url" content="https://pure419.github.io/wen-ti-hui-zong.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://pure419.github.io/assets/css/style.css?v=6fbb1e8931a5afe843374fd67c192c86"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://pure419.github.io/wen-ti-hui-zong.html"},"headline":"问题汇总","datePublished":"2024-06-03T21:47","dateModified":"2024-06-03T21:47","description":"存在的问题 重构 出现的原因： 认为编码器对于正常事件有较低重构误差而异常事件的重构误差更大，以此能够分辨正常事件和异常事件 问题 正常样本和异常样本都可以很好地重构，从而无法发现异常值 它们通常陷入“Identity Shortcut”，”相同捷径”问题是指在机器学习中模型陷入将输入数据直接返回作为输出的低效策略。这种策略使得模型难以检测异常样本，并且在统一数据分布下尤为明显。学习”相同捷径”似乎是一种简单而低成本的解决方案，但它无法对输入数据进行有意义的转换和学习。 半监督学习 出现的原因： 减少数据标注工作，只需要正常事件即可 现实生活中异常事件有无限种可能，因此现实生活中非正常的事件即为异常事件的理念应用到训练模式中 问题： 在仅对正常数据进行训练的模型在将异常数据注入训练时无法保持稳健。 通常会触发误报，因为仅通过正常视频不借助任何先验知识本质上不适合定义正常和异常 忽略正常和异常间的关系 正常事件也是无限的，未见过的正常事件很有可能被识别为异常 记忆机制MEMORY 出现的原因： 由于正常（或异常）事件具有多样性，单靠一种网络难以表示所有正常（或异常）事件，因此加入记忆机制，存储不同类型正常（或异常）事件的原型（学习不同类型分布）。一个事件通过相似性对比可以表示为多个原型的组合 问题： 建立存储体需要额外的存储空间* 来自主观假设的固定原型数量忽略了数据特征差异和多样性* *观点来自于： Dynamic Local Aggregation Network with Adaptive Clusterer for Anomaly Detection 一些文献的memory为存储离线训练好的静态原型，难以适应未知事件 MIL学习 出现的原因： 能够对只有视频级别标签的数据进行训练，得到片段级别的标签 问题： MIL 会出现许多误报，因为它很容易偏向于具有简单上下文的异常片段，被具有相同偏差的正常片段所迷惑，并错过具有不同模式的异常、 两阶段自训练的方式，不可靠的伪标签会影响后续模型的训练 伪标签生成器中使用的排名损失忽略了异常事件的完整性。原因是，一个异常视频可能包含多个异常片段，但 MIL 旨在仅检测最有可能的一个&hellip;","author":{"@type":"Person","name":"lijun","url":"https://pure419.github.io/authors/lijun/"},"publisher":{"@type":"Organization","name":"lijun"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://pure419.github.io/">lijun note</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li class="active"><a href="https://pure419.github.io/wen-ti-hui-zong.html" target="_blank">问题汇总</a></li><li><a href="https://pure419.github.io/test.html" target="_self">test</a></li></ul></nav></header><main><article class="post"><div class="hero"><header class="hero__content"><div class="wrapper"><div class="post__meta"><time datetime="2024-06-03T21:47">June 3, 2024</time></div><h1>问题汇总</h1><div class="post__meta post__meta--author"><a href="https://pure419.github.io/authors/lijun/" class="feed__author">lijun</a></div></div></header></div><div class="wrapper post__entry"><ul><li><h1 id="存在的问题">存在的问题</h1><ul><li><h2 id="重构">重构</h2><ul><li><h3 id="出现的原因：">出现的原因：</h3><ul><li>认为编码器对于正常事件有较低重构误差而异常事件的重构误差更大，以此能够分辨正常事件和异常事件</li></ul></li><li><h3 id="问题">问题</h3><ul><li>正常样本和异常样本都可以很好地重构，从而无法发现异常值</li><li>它们通常陷入“Identity Shortcut”，”相同捷径”问题是指在机器学习中模型陷入将输入数据直接返回作为输出的低效策略。这种策略使得模型难以检测异常样本，并且在统一数据分布下尤为明显。学习”相同捷径”似乎是一种简单而低成本的解决方案，但它无法对输入数据进行有意义的转换和学习。</li></ul></li></ul></li><li><h2 id="半监督学习">半监督学习</h2><ul><li><h3 id="出现的原因：-1">出现的原因：</h3><ul><li>减少数据标注工作，只需要正常事件即可</li><li>现实生活中异常事件有无限种可能，因此现实生活中非正常的事件即为异常事件的理念应用到训练模式中</li></ul></li><li><h3 id="问题：">问题：</h3><ul><li>在仅对正常数据进行训练的模型在将异常数据注入训练时无法保持稳健。</li><li>通常会触发误报，因为仅通过正常视频不借助任何先验知识本质上不适合定义正常和异常</li><li>忽略正常和异常间的关系</li><li>正常事件也是无限的，未见过的正常事件很有可能被识别为异常</li></ul></li></ul></li><li><h2 id="记忆机制memory">记忆机制MEMORY</h2><ul><li><h3 id="出现的原因：-2">出现的原因：</h3><ul><li>由于正常（或异常）事件具有多样性，单靠一种网络难以表示所有正常（或异常）事件，因此加入记忆机制，存储不同类型正常（或异常）事件的原型（学习不同类型分布）。一个事件通过相似性对比可以表示为多个原型的组合</li></ul></li><li><h3 id="问题：-1">问题：</h3><ul><li>建立存储体需要额外的存储空间*</li><li>来自主观假设的固定原型数量忽略了数据特征差异和多样性*<ul><li>*观点来自于： Dynamic Local Aggregation Network with Adaptive Clusterer for Anomaly Detection</li></ul></li><li>一些文献的memory为存储离线训练好的静态原型，难以适应未知事件</li></ul></li></ul></li><li><h2 id="mil学习">MIL学习</h2><ul><li><h3 id="出现的原因：-3">出现的原因：</h3><ul><li>能够对只有视频级别标签的数据进行训练，得到片段级别的标签</li></ul></li><li><h3 id="问题：-2">问题：</h3><ul><li>MIL 会出现许多误报，因为它很容易偏向于具有简单上下文的异常片段，被具有相同偏差的正常片段所迷惑，并错过具有不同模式的异常、</li><li>两阶段自训练的方式，不可靠的伪标签会影响后续模型的训练</li><li>伪标签生成器中使用的排名损失忽略了异常事件的完整性。原因是，一个异常视频可能包含多个异常片段，但 MIL 旨在仅检测最有可能的一个</li><li>正包内的大量正常实例被忽略，被正常实例包围的异常实例难以被检测。</li></ul></li></ul></li><li><h2 id="视频字幕帮助">视频字幕帮助</h2><ul><li><h3 id="出现的原因：-4">出现的原因：</h3><ul><li>能够对只有视频级别标签的数据进行训练，得到片段级别的标签</li></ul></li><li><h3 id="问题：-3">问题：</h3><ul><li>文字描述包含的信息有限，</li><li>抽取语义到的语义特征可以直接用特征向量表示即可，语义特征转换为文字，以及文字再次转换为抽象特征需要耗费额外的计算量，降低模型的效率</li></ul></li></ul></li><li><h2 id="筛选不确定样本">筛选不确定样本</h2><ul><li><h3 id="出现的原因">出现的原因</h3><ul><li>如果使用伪标签生成环节，不确定的标签会影响后续模型训练，因此有必要对不确定样本进行筛选</li></ul></li><li><h3 id="问题-1">问题</h3><ul><li>现有方法多为直接过滤丢弃不确定样本，这导致部分信息缺失。假如被丢弃的样本中含有关键信息，则会直接影响结果。</li></ul></li></ul></li><li><h2 id="多尺度">多尺度</h2><ul><li><h3 id="出现的原因-1">出现的原因</h3><ul><li>为了有效感知时间和空间局部和全局关系。将一个视频片段以不同尺度划分为块，学习不同划分方式下小块之间的关系。学习多个小片段之间的关系。</li></ul></li><li><h3 id="问题-2">问题</h3><ul><li>计算量过高，同一个视频小片段，重复分成n次，数据量成倍增长。冗余、庞大</li><li>分块不够智能</li></ul></li></ul></li><li><h2 id="整体">整体</h2><ul><li><h3 id="识别依据">识别依据</h3><ul><li>将异常特征幅度推向更大，并将正常特征幅度推向相反的方向。在相同的视频序列或相似的场景中，异常特征可能比正常特征具有更大的幅度</li><li>//事实上，特征量级还取决于视频的其他属性，例如物体运动、场景中物体和人的数量等</li></ul></li><li><h3 id="缺少上下文关系、高级视觉特征、语义信息">缺少上下文关系、高级视觉特征、语义信息</h3><ul><li>现有方法大多遵循帧重建或帧预测的路线，<strong>缺乏对视频中高级视觉特征和时间上下文关系的挖掘</strong>和学习限制了这两种方法的进一步性能</li><li>以前的工作仅考虑时空特征。在许多复杂的现实场景中，此类视觉特征无法进一步捕获视频语义信息</li><li>一些方法由于缺乏全局上下文感知和对异常帧的具体关注，它们通常难以处理异常帧仅占一小部分的长视频，只在短视频上表现较好</li></ul></li><li><h3 id="场景">场景</h3><ul><li>一些异常与场景相关。如何检测场景相关异常，同时防止背景偏差是需要关注的问题。仅关注运动或时间信息，甚至排除外观信息会导致对复杂场景的不完整理解</li><li>通常会忽略场景变化的影响（变暗或者突然有光照过来等等），需要考虑复杂场景，光线复杂，人员复杂，现实情况中会有抖动，模糊，图像中断，卡帧掉帧，遮挡等其他噪声</li><li>一些对象会出境（只露出身体的一小部分），这时需要模型能够自动补全</li><li>很容易受到背景纹理和物体尺度变化等无关因素的干扰，从而导致误检率增加</li></ul></li><li><h3 id="帧输入问题">帧输入问题</h3><ul><li>只采样几帧以避免大量的计算，通常会限制识别性能。</li><li><h4 id="动态采样（学习如何采样）">动态采样（学习如何采样）</h4><ul><li>不重要的帧的信息完全丢失，完全放弃了网络认为不重要的信息，</li><li>引入策略网络为每个样本做出筛选，会产生额外的计算并、变得复杂。并且消耗时间，</li></ul></li></ul></li><li><h3 id="正常和异常样本的表示">正常和异常样本的表示</h3><ul><li>正常事件和异常事件均具有多样性。如何表示多样化的事件且不泛化到另一个类是一个挑战</li><li>从不同正常模式收集的样本是不平衡的，因为某些正常活动可能显得非常稀疏[46]。如何处理罕见但正常的活动也具有挑战性</li><li>重建不同正常事件和检测未知异常之间重构误差大小的权衡。</li><li>现有方法往往存在类内差异大，类间差异小的问题</li><li>很难使用单一的静态网络架构从不同的异常模式中提取有用的信息，因此需要非单一的动态网络架构</li></ul></li><li><h3 id="跨域问题">跨域问题</h3><ul><li>大多数跨域视频异常检测工作假设至少有很少的与任务相关的目标域训练数据可用于从源到目标域的适应。能否实现不需要任何目标域数据训练就能直接在新域中表现良好。</li><li>现有方法难以在有限训练数据下检测新的场景和新的异常</li></ul></li><li><h3 id="与相机的距离">与相机的距离</h3><ul><li>相同运动幅度，远离相机的物体运动数值上要更小，靠近相机的物体数值上更大，现有方法很少有人考虑这个问题</li><li>异常空间大小的影响被忽视了，现实生活中异常事件在监控中的画面有大有小</li></ul></li><li><h3 id="可解释性">可解释性</h3><ul><li>没有模型可解释性，就无法准确评估其严重程度，也难以应对跨域问题</li><li></li></ul></li></ul></li></ul></li><li><h1 id="我想解决的问题">我想解决的问题</h1><ul><li><h2 id="未能有效提取长时间段上下文语义特征">未能有效提取长时间段上下文语义特征</h2><ul><li>大部分方法还是局限于学习短时间的单独对象的运动模式，未能有效提取长时间段的上下文语义特征，这导致短时间的异常事件能被有效检测，而长时间的异常事件难以被检测。</li><li>如下图所示，现有模型往往在检测虐待、抓捕、打架、抢劫这种具有强烈运动幅度、短时间内发生的异常事件表现良好。而在检测逮捕、纵火这类长时间内的异常事件时表现较差。</li><li><figure class="post__image"><img loading="lazy" src="../assets/image_1690797894352_0.png" alt="image.png" data-is-external-image="true"></figure>{:height 321, :width 542}</li><li><figure class="post__image"><img loading="lazy" src="../assets/image_1693798496456_0.png" alt="image.png" data-is-external-image="true"></figure></li></ul></li><li><h2 id="模型可解释性、跨域能力不足">模型可解释性、跨域能力不足</h2><ul><li>导致这一问题的原因之一就是现有方法未能有效提取上下文语义特征</li><li>如图所示，跨域性能有待提高<ul><li><figure class="post__image"><img loading="lazy" src="../assets/image_1690877474826_0.png" alt="image.png" data-is-external-image="true"></figure></li><li><figure class="post__image"><img loading="lazy" src="../assets/image_1690877361646_0.png" alt="image.png" data-is-external-image="true"></figure></li><li><figure class="post__image"><img loading="lazy" src="../assets/image_1690877853304_0.png" alt="image.png" data-is-external-image="true"></figure></li></ul></li></ul></li><li><h2 id="对象画面不全（只露出身体的一小部分）时检测结果较差">对象画面不全（只露出身体的一小部分）时检测结果较差</h2><ul><li>现有方法在对象出现画面不全（只露出身体的一小部分）时，检测结果较差。如图所示，复现的模型，在识别对象只露出小于一半的身体时难以检测出异常事件。</li><li>MIST模型<ul><li><figure class="post__image"><img loading="lazy" src="../assets/image_1690877128978_0.png" alt="image.png" data-is-external-image="true"></figure></li></ul></li><li>SSRL模型<ul><li><figure class="post__image"><img loading="lazy" src="../assets/image_1690884298823_0.png" alt="image.png" data-is-external-image="true"></figure></li></ul></li></ul></li><li><h2 id="多尺度学习分块不够智能、计算冗余">多尺度学习分块不够智能、计算冗余</h2><ul><li>多尺度学习能够有效兼顾到视频全局和局部的关系。同时由于监控视频中异常事件发生存在尺度变化。即事件区域有可能占整个视频的大部分画面，也有可能只在一小部分区域发生，因此多尺度学习的方式能够有效捕获到关键数据。但是现有多尺度检测的方法存在一定问题，如下图所示。该方法在空间层面会把一个片段视频划分为1，6，12…个小块，之后会将所有这些数据全部拼接起来进行学习，造成计算冗余。此外，分块是无目的地将画面平均划分为N个小块，这很有可能将关键对象分割在多个块内,导致提取不精确。</li><li><figure class="post__image"><img loading="lazy" src="../assets/image_1690266250049_0.png" alt="image.png" data-is-external-image="true"></figure></li><li>该模型复杂度如下所示，参数量和计算量都比较大</li><li><figure class="post__image"><img loading="lazy" src="../assets/image_1691040988524_0.png" alt="image.png" data-is-external-image="true"></figure></li></ul></li></ul></li><li></li></ul></div><footer class="wrapper post__footer"><p class="post__last-updated">This article was updated on June 3, 2024</p><div class="post__share"></div><div class="post__bio bio"><div><h3 class="bio__name"><a href="https://pure419.github.io/authors/lijun/" rel="author">lijun</a></h3></div></div></footer></article><nav class="post__nav"><div class="post__nav-inner"><div class="post__nav-prev"><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://pure419.github.io/assets/svg/svg-map.svg#arrow-prev"/></svg> <a href="https://pure419.github.io/test.html" class="post__nav-link" rel="prev"><span>Previous</span> test</a></div></div></nav></main><footer class="footer"><div class="footer__copyright"><p>Powered by Publii</p></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://pure419.github.io/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script defer="defer" src="https://pure419.github.io/assets/js/scripts.min.js?v=f47c11534595205f20935f0db2a62a85"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>